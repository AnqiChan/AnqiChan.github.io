---
title: "DataWhale - AI硬件与机器人 - 1"
excerpt_separator: "<!--more-->"
categories:
  - Blog
tags:
  - Post Formats
  - readability
  - standard
---

### **1. 目前主流的 VLA（Vision-Language-Action）有哪些？参数量、计算资源、落地情况？未来可努力方向？**

**主流 VLA 模型包括：**

* **RT-1 / RT-2（Google DeepMind）**：

  * 参数量：RT-2 是基于 ViT + PaLM（数百亿参数）
  * 训练资源：上万小时的视频+机器人数据 + TPU Pod 大规模训练
  * 部署资源：需边缘加速推理（轻量版已尝试）
  * 落地情况：用于实验室内多个任务（抓取、分类、开门等）

* **Gato（DeepMind）**：

  * 参数量：1.2B – 6B
  * 多模态控制（游戏、机器人、对话）
  * 主要仍在研究阶段，落地少

* **Open-X Embodiment + RT-X（Google Brain）**：

  * 参数量不固定（取决于集成）
  * 联合训练多个机器人平台
  * 是通向“通用机器人控制”方向的尝试

* **Code-as-Policies (CaP)**：

  * 参数量：使用 Codex、GPT-3.5 等基础模型
  * 控制逻辑用代码生成，执行靠小模型或 rule-based
  * 在家庭机器人中已有 demo 落地

* **VIMA (Meta AI)**：

  * 模仿学习+token级 multimodal融合
  * 参数量数亿到十亿，训练数据量较少
  * 仍为模拟环境验证，未大规模部署

**计算资源**：
训练普遍需要 GPU/TPU 数百卡小时以上，推理根据模型裁剪程度从 Jetson 到 A100 不等。

**真正落地的**：
目前真正做到“商用”或“产品级”的很少，多数停留在研究/原型，如：

* RT-2 在 Google 实验室日常任务中落地（限制场景）
* 些许公司在用类 RT 模型做机械臂 pick-and-place demo（如 Covariant、Boston Dynamics 实验室）

**未来可努力方向**：

* **小模型压缩 / distillation 落地端侧**
* **统一多模态序列学习**（语言+视觉+动作+触觉）
* **数据共享联盟**，解决模态缺乏和隐私问题
* **闭环反馈学习机制**：机器人自主试错+回传改进模型
* **更好的任务泛化和“zero-shot实际世界能力”**

---

### **2. 主流改进方向如 3DGS、触觉 VTLA、多级控制、大小脑结构，你怎么看？还有哪些方向可改？**

**个人点评如下：**

* **注入 3DGS / 点云信息**：非常必要。
  视觉+深度/点云 = 更好理解三维几何关系，对 manipulation 至关重要。

* **VTLA（视觉+触觉+语言+行动）**：
  是具身智能下一步的关键。纯视觉常常无法判断是否“抓牢”、“摩擦合适”等，触觉补充信号闭环。

* **多级 VLA 控制**：
  借鉴分层策略：高层语言计划 -> 中层目标决策 -> 低层运动控制。既减小搜索空间，也更具通用性。

* **大小脑结构**：
  “大脑”用于思考规划（如 LLM），小脑负责精细执行（如 model predictive control 或传统控制器）。是拟人结构的一个有力尝试。

**还能改进的方向包括：**

* **更好的世界模型（World Model）建模**：例如 DreamerV3 式 latent imagination，用于规划和预测。

* **内嵌语言调试机制（Language-assisted Debugging）**：使机器人能“自我解释”失败原因，并用语言与人类协商。

* **时间尺度建模（temporal abstraction）**：统一短期动作控制与长期目标设定。

* **非结构化知识注入（common-sense、物理知识）**：如 COMET、ATOMIC 这类常识模型作为辅助模块。

---

### **3. 强化学习、MPC 会不会被 VLA 取代？**

不会被“取代”，但**地位在变化**。现在是一个更偏 **融合式范式**。

* VLA（尤其是大模型）通过利用大规模数据与语言理解能力，实现了**更强的泛化与zero-shot能力**，适用于 open-world 任务。

* **强化学习（RL）** 和 **模型预测控制（MPC）**：

  * 在 **精细控制、局部优化、连续动作空间**中仍有不可替代性
  * 尤其是在**闭环反馈执行**中，稳定性比 LLM 生成动作强很多

**趋势是：**

* RL/MPC 更像“小脑”，用于细粒度控制、稳定执行。
* VLA 模型或 LLM 更像“大脑”，用于感知、规划和任务理解。

所以它们不是彼此淘汰，而是“协同融合”成为主流方向。

---

### **4. 用两句话总结：VLA 与 强化学习**

* **VLA 是一种通过视觉和语言理解来指导行动的大模型系统，强调泛化与多模态融合能力。**

* **强化学习是通过环境反馈来学习最优策略的算法体系，更强调试错优化和稳定执行控制。**

---
